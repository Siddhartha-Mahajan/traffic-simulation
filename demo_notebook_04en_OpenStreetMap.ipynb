{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uxsim import *\n",
    "\n",
    "# Define the main simulation\n",
    "# Units are standardized to seconds (s) and meters (m)\n",
    "W = World(\n",
    "    name=\"\",    # Scenario name\n",
    "    deltan=5,   # Simulation aggregation unit delta n\n",
    "    tmax=1200,  # Total simulation time (s)\n",
    "    print_mode=1, save_mode=1, show_mode=0,    # Various options\n",
    "    random_seed=0    # Set the random seed\n",
    ")\n",
    "\n",
    "# Define the scenario\n",
    "W.addNode(\"orig1\", 0, 0) # Create a node\n",
    "W.addNode(\"orig2\", 0, 2)\n",
    "W.addNode(\"merge\", 1, 1)\n",
    "W.addNode(\"dest\", 2, 1)\n",
    "W.addLink(\"link1\", \"orig1\", \"merge\", length=1000, free_flow_speed=20) # Create a link\n",
    "W.addLink(\"link2\", \"orig2\", \"merge\", length=1000, free_flow_speed=20)\n",
    "W.addLink(\"link3\", \"merge\", \"dest\", length=1000, free_flow_speed=20)\n",
    "W.adddemand(\"orig1\", \"dest\", 0, 1000, 0.45) # Create OD traffic demand\n",
    "W.adddemand(\"orig2\", \"dest\", 400, 1000, 0.6)\n",
    "\n",
    "# Run the simulation to the end\n",
    "W.exec_simulation()\n",
    "\n",
    "# Print summary of simulation result\n",
    "W.analyzer.print_simple_stats()\n",
    "\n",
    "# Visualize snapshots of network traffic state for several timesteps\n",
    "W.analyzer.network(100, detailed=1, network_font_size=12)\n",
    "W.analyzer.network(600, detailed=1, network_font_size=12)\n",
    "W.analyzer.network(800, detailed=1, network_font_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from uxsim import *\n",
    "import random\n",
    "\n",
    "################################################\n",
    "# Environment of gymnasium\n",
    "\n",
    "class TrafficSim(gym.Env):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        traffic scenario: 4-legged intersection with 2 phase signal.\n",
    "        action 1: greenlight for direction 1\n",
    "        action 2: greenlight for direction 2\n",
    "        state: number of waiting vehicles for each incoming link\n",
    "        reward: negative of difference of total waiting vehicles\n",
    "        \"\"\"\n",
    "\n",
    "        #action\n",
    "        self.n_action = 2\n",
    "        self.action_space = gym.spaces.Discrete(self.n_action)\n",
    "\n",
    "        #state\n",
    "        self.n_state = 4\n",
    "        low = np.array([0 for i in range(self.n_state)])\n",
    "        high = np.array([100 for i in range(self.n_state)])\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        reset the env\n",
    "        \"\"\"\n",
    "        seed = None #demand is always random\n",
    "        self.W = World(\n",
    "            name=\"\",\n",
    "            deltan=5,\n",
    "            tmax=3600,\n",
    "            print_mode=0, save_mode=0, show_mode=1,\n",
    "            random_seed=seed,\n",
    "            duo_update_time=99999\n",
    "        )\n",
    "        random.seed(seed)\n",
    "\n",
    "        #network definition\n",
    "        self.II = self.W.addNode(\"Intersection\", 0, 0, signal=[60,60])\n",
    "        self.EE = self.W.addNode(\"E\", 1, 0)\n",
    "        self.WW = self.W.addNode(\"W\", -1, 0)\n",
    "        self.SS = self.W.addNode(\"S\", 0, 1)\n",
    "        self.NN = self.W.addNode(\"N\", 0, -1)\n",
    "        self.W.addLink(\"EI\", self.EE, self.II, length=500, free_flow_speed=10, jam_density=0.2, signal_group=0)\n",
    "        self.W.addLink(\"WI\", self.WW, self.II, length=500, free_flow_speed=10, jam_density=0.2, signal_group=0)\n",
    "        self.W.addLink(\"SI\", self.SS, self.II, length=500, free_flow_speed=10, jam_density=0.2, signal_group=1)\n",
    "        self.W.addLink(\"NI\", self.NN, self.II, length=500, free_flow_speed=10, jam_density=0.2, signal_group=1)\n",
    "        self.W.addLink(\"IE\", self.II, self.EE, length=500, free_flow_speed=10, jam_density=0.2)\n",
    "        self.W.addLink(\"IW\", self.II, self.WW, length=500, free_flow_speed=10, jam_density=0.2)\n",
    "        self.W.addLink(\"IS\", self.II, self.SS, length=500, free_flow_speed=10, jam_density=0.2)\n",
    "        self.W.addLink(\"IN\", self.II, self.NN, length=500, free_flow_speed=10, jam_density=0.2)\n",
    "\n",
    "        #random demand definition\n",
    "        dt = 30\n",
    "        for t in range(0, 3600, dt):\n",
    "            self.W.adddemand(self.EE, self.WW, t, t+dt, random.uniform(0, 0.6))\n",
    "            self.W.adddemand(self.WW, self.EE, t, t+dt, random.uniform(0, 0.6))\n",
    "            self.W.adddemand(self.SS, self.NN, t, t+dt, random.uniform(0, 0.6))\n",
    "            self.W.adddemand(self.NN, self.SS, t, t+dt, random.uniform(0, 0.6))\n",
    "\n",
    "        #initial observation\n",
    "        observation = np.array([0 for i in range(self.n_state)])\n",
    "\n",
    "        #log\n",
    "        self.log_state = []\n",
    "        self.log_reward = []\n",
    "\n",
    "        return observation, None\n",
    "\n",
    "    def comp_state(self):\n",
    "        \"\"\"\n",
    "        compute the current state\n",
    "        \"\"\"\n",
    "        vehicles_per_links = {}\n",
    "        for l in self.II.inlinks.values():\n",
    "            vehicles_per_links[l] = l.num_vehicles_queue #l.num_vehicles_queue: the number of vehicles in queue in link l\n",
    "        return list(vehicles_per_links.values())\n",
    "\n",
    "    def comp_n_veh_queue(self):\n",
    "        return sum(self.comp_state())\n",
    "\n",
    "    def step(self, action_index):\n",
    "        \"\"\"\n",
    "        proceed env by 1 step = 30 seconds\n",
    "        \"\"\"\n",
    "\n",
    "        n_queue_veh_old = self.comp_n_veh_queue()\n",
    "\n",
    "        #change signal by action\n",
    "        if action_index == 0:\n",
    "            self.II.signal_phase = 0\n",
    "            self.II.signal_t = 0\n",
    "        elif action_index == 1:\n",
    "            self.II.signal_phase = 1\n",
    "            self.II.signal_t = 0\n",
    "\n",
    "        #traffic dynamics. execute simulation for 30 seconds\n",
    "        if self.W.check_simulation_ongoing():\n",
    "            self.W.exec_simulation(duration_t=30)\n",
    "\n",
    "        #observe state\n",
    "        observation = np.array(self.comp_state())\n",
    "\n",
    "        #compute reward\n",
    "        n_queue_veh = self.comp_n_veh_queue()\n",
    "        reward = -(n_queue_veh-n_queue_veh_old)\n",
    "\n",
    "        #check termination\n",
    "        done = False\n",
    "        if self.W.check_simulation_ongoing() == False:\n",
    "            done = True\n",
    "\n",
    "        #log\n",
    "        self.log_state.append(observation)\n",
    "        self.log_reward.append(reward)\n",
    "\n",
    "        return observation, reward, done, {}, None\n",
    "\n",
    "################################################\n",
    "# DQN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = TrafficSim()\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super().__init__()\n",
    "        n_neurals = 64\n",
    "        n_layers = 2\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(n_observations, n_neurals))\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(n_neurals, n_neurals))\n",
    "        self.layer_last = nn.Linear(n_neurals, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.layer_last(x)\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row. second column on max result is index of where max element was found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for detailed explanation). This converts batch-array of Transitions to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken. These are the actions which would've been taken for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "################################################\n",
    "# (hyper)parameters\n",
    "\n",
    "# the number of transitions sampled from the replay buffer\n",
    "BATCH_SIZE = 128\n",
    "# the discount factor as mentioned in the previous section\n",
    "GAMMA = 0.99\n",
    "# the starting value of epsilon\n",
    "EPS_START = 0.9\n",
    "# the final value of epsilon\n",
    "EPS_END = 0.05\n",
    "# the rate of exponential decay of epsilon, higher means a slower decay\n",
    "EPS_DECAY = 1000\n",
    "# the update rate of the target network\n",
    "TAU = 0.005\n",
    "# the learning rate of the ``AdamW`` optimizer\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "################################################\n",
    "# Execute DRL\n",
    "num_episodes = 40\n",
    "\n",
    "log_states = []\n",
    "log_epi_average_delay = []\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get it's state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    log_states.append([])\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        log_states[-1].append(state)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            log_epi_average_delay.append(env.W.analyzer.average_delay)\n",
    "            print(f\"{i_episode}:[{log_epi_average_delay[-1] : .3f}]\", end=\" \")\n",
    "            break\n",
    "\n",
    "    if i_episode%10 == 0 or i_episode == num_episodes-1:\n",
    "        env.W.analyzer.print_simple_stats(force_print=True)\n",
    "        env.W.analyzer.time_space_diagram_traj([\"EI\", \"WI\", \"SI\", \"NI\"], figsize=(12,2))\n",
    "        for t in list(range(0,env.W.TMAX,int(env.W.TMAX/6))):\n",
    "            env.W.analyzer.network(t, detailed=1, network_font_size=0, figsize=(2,2))\n",
    "\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.plot(log_epi_average_delay, \"r.\")\n",
    "        plt.xlabel(\"episode\")\n",
    "        plt.ylabel(\"average delay (s)\")\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W.analyzer.network_fancy(animation_speed_inverse=15,network_font_size=1, sample_ratio=0.3, interval=3, trace_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uxsim import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # simulation world\n",
    "    W = World(\n",
    "        name=\"\",\n",
    "        deltan=5,\n",
    "        tmax=1200,\n",
    "        print_mode=1, save_mode=1, show_mode=1,\n",
    "        random_seed=0\n",
    "    )\n",
    "\n",
    "    # scenario\n",
    "    W.addNode(\"orig1\", 0, 0)\n",
    "    W.addNode(\"orig2\", 0, 2)\n",
    "    W.addNode(\"merge\", 1, 1)\n",
    "    W.addNode(\"dest\", 2, 1)\n",
    "    link1 = W.addLink(\"link1\", \"orig1\", \"merge\", length=1000, free_flow_speed=20, jam_density=0.2, merge_priority=0.5)\n",
    "    link2 = W.addLink(\"link2\", \"orig2\", \"merge\", length=1000, free_flow_speed=20, jam_density=0.2, merge_priority=2)\n",
    "    link3 = W.addLink(\"link3\", \"merge\", \"dest\", length=1000, free_flow_speed=20, jam_density=0.2)\n",
    "    W.adddemand(\"orig1\", \"dest\", 0, 1000, 0.4)\n",
    "    W.adddemand(\"orig2\", \"dest\", 300, 1000, 0.6)\n",
    "\n",
    "    # execute simulation\n",
    "    while W.check_simulation_ongoing():\n",
    "        W.exec_simulation(duration_t=100) # run simulation for 100 seconds\n",
    "\n",
    "        print(\"\\t\", link1.num_vehicles_queue, \"/\", link1.num_vehicles)    #print the number of vehicles in the queue and on the link\n",
    "        print(\"\\t\", link1.flow, link1.density, link1.speed) #print the flow, density, and speed of the link\n",
    "\n",
    "        if W.on_time(600):\n",
    "            link2.merge_priority = 0.2    #lower the merge priority of link2\n",
    "\n",
    "        if W.on_time(800):\n",
    "            link1.free_flow_speed = 5    #lower the free flow speed of link1\n",
    "\n",
    "        if W.on_time(1000):\n",
    "            link3.capacity_in = link3.capacity/2    #lower the capacity of link3\n",
    "\n",
    "    # visualize\n",
    "    W.analyzer.print_simple_stats()\n",
    "    W.analyzer.time_space_diagram_traj_links([[\"link1\", \"link3\"], [\"link2\", \"link3\"]])\n",
    "    W.analyzer.macroscopic_fundamental_diagram()\n",
    "\n",
    "    # output results\n",
    "    print(W.analyzer.basic_to_pandas()) #if the model parameters are changed dynamically, the calculation of free travel time and delay may becomes inappropriate\n",
    "    print(W.analyzer.od_to_pandas())\n",
    "    print(W.analyzer.mfd_to_pandas())\n",
    "    print(W.analyzer.link_to_pandas())\n",
    "    print(W.analyzer.link_traffic_state_to_pandas())\n",
    "    print(W.analyzer.vehicles_to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uxsim as UX\n",
    "from uxsim.ResultGUIViewer import ResultGUIViewer\n",
    "\n",
    "W = UX.World(\n",
    "    name=\"\",\n",
    "    deltan=5,\n",
    "    tmax=7200,\n",
    "    print_mode=1, save_mode=1, show_mode=0,\n",
    "    random_seed=0,\n",
    ")\n",
    "\n",
    "# scenario\n",
    "#automated network generation\n",
    "#deploy nodes as an imax x jmax grid\n",
    "imax = 9\n",
    "jmax = 9\n",
    "nodes = {}\n",
    "for i in range(imax):\n",
    "    for j in range(jmax):\n",
    "        nodes[i,j] = W.addNode(f\"n{(i,j)}\", i, j, flow_capacity=1.6)\n",
    "\n",
    "#create links between neighborhood nodes\n",
    "links = {}\n",
    "for i in range(imax):\n",
    "    for j in range(jmax):\n",
    "        if i != imax-1:\n",
    "            links[i,j,i+1,j] = W.addLink(f\"l{(i,j,i+1,j)}\", nodes[i,j], nodes[i+1,j], length=1000, free_flow_speed=20, jam_density=0.2)\n",
    "        if i != 0:\n",
    "            links[i,j,i-1,j] = W.addLink(f\"l{(i,j,i-1,j)}\", nodes[i,j], nodes[i-1,j], length=1000, free_flow_speed=20, jam_density=0.2)\n",
    "        if j != jmax-1:\n",
    "            links[i,j,i,j+1] = W.addLink(f\"l{(i,j,i,j+1)}\", nodes[i,j], nodes[i,j+1], length=1000, free_flow_speed=20, jam_density=0.2)\n",
    "        if j != 0:\n",
    "            links[i,j,i,j-1] = W.addLink(f\"l{(i,j,i,j-1)}\", nodes[i,j], nodes[i,j-1], length=1000, free_flow_speed=20, jam_density=0.2)\n",
    "\n",
    "#generate traffic demand between the boundary nodes\n",
    "demand_flow = 0.2\n",
    "demand_duration = 3600\n",
    "for n1 in [(0,j) for j in range(int(jmax/3), int(jmax*2/3))]:\n",
    "    for n2 in [(imax-1,j) for j in range(int(jmax/3), int(jmax*2/3))]:\n",
    "        W.adddemand(nodes[n2], nodes[n1], 0, demand_duration, demand_flow)\n",
    "        W.adddemand(nodes[n1], nodes[n2], 0, demand_duration, demand_flow)\n",
    "for n1 in [(i,0) for i in range(int(imax/3), int(imax*2/3))]:\n",
    "    for n2 in [(i,jmax-1) for i in range(int(imax/3), int(imax*2/3))]:\n",
    "        W.adddemand(nodes[n2], nodes[n1], 0, demand_duration, demand_flow)\n",
    "        W.adddemand(nodes[n1], nodes[n2], 0, demand_duration, demand_flow)\n",
    "\n",
    "# Run the simulation to the end\n",
    "W.exec_simulation()\n",
    "\n",
    "# Print summary of simulation result\n",
    "W.analyzer.print_simple_stats()\n",
    "\n",
    "# Launch the GUI viewer\n",
    "ResultGUIViewer.launch_World_viewer(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.analyzer.network_anim(animation_speed_inverse=15,network_font_size=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uxsim import *\n",
    "from uxsim.OSMImporter import OSMImporter\n",
    "\n",
    "W = World(\n",
    "    name=\"\",\n",
    "    deltan=5,\n",
    "    tmax=7200,\n",
    "    print_mode=1, save_mode=1, show_mode=0, \n",
    "    random_seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, links = OSMImporter.import_osm_data(north=35.817, south=35.570, east=139.881, west=139.583, custom_filter='[\"highway\"~\"motorway\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows the imported network data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSMImporter.osm_network_visualize(nodes, links, show_link_name=0)\n",
    "OSMImporter.osm_network_visualize(nodes, links, show_link_name=0, xlim=[139.75, 139.76], ylim=[35.60, 35.615], figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the raw data is too detailed and not suitable for UXsim simulation. For example, many intersections of OSM consists of 4 nodes and may create strange traffic simulation results such as gridlocks.\n",
    "    \n",
    "Therefore, postprocessing is required to make the network suitable for simulation as follows. First, it aggregates the network by merging nodes that are closer than the threshold (0.05 degree ~= 500 m). Second, we add reverse links for each link to eliminate dead-end nodes as much as possible. WIthout it, a lot of vehicles will lost their way and loiter the network randomly. Please be aware that in this postprocessing the original network topology is not preserved rigorously. This function is just for convenience; if you need rigorous network data, you have to manually adjust it.\n",
    "\n",
    "`OSMImporter.osm_network_to_World` will load the postprocessed network into the World."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, links = OSMImporter.osm_network_postprocessing(nodes, links, node_merge_threshold=0.005, node_merge_iteration=5, enforce_bidirectional=True)\n",
    "OSMImporter.osm_network_to_World(W, nodes, links, default_jam_density=0.2, coef_degree_to_meter=111000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSMImporter.osm_network_visualize(nodes, links, show_link_name=0)\n",
    "OSMImporter.osm_network_visualize(nodes, links, show_link_name=0, xlim=[139.75, 139.76], ylim=[35.60, 35.615], figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the network data is significantly simplified. For example, the highway junction is represented by fewer number of nodes which is convinient. You can see that this is still similar to the real network shown before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand\n",
    "\n",
    "The travel demand is now defined using coordinates. Below add demand from a circular area to another circular area. It represents demand to central Tokyo from surroundings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.adddemand_area2area(139.70, 35.60, 0, 139.75, 35.68, 0.05, 0, 3600, volume=2500)\n",
    "W.adddemand_area2area(139.65, 35.70, 0, 139.75, 35.68, 0.05, 0, 3600, volume=2500)\n",
    "W.adddemand_area2area(139.75, 35.75, 0, 139.75, 35.68, 0.05, 0, 3600, volume=2500)\n",
    "W.adddemand_area2area(139.85, 35.70, 0, 139.75, 35.68, 0.05, 0, 3600, volume=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation and results\n",
    "\n",
    "Now you can execute the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.exec_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uxsim as UX\n",
    "from uxsim.ResultGUIViewer import ResultGUIViewer\n",
    "ResultGUIViewer.launch_World_viewer(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.analyzer.print_simple_stats()\n",
    "W.analyzer.network_anim(animation_speed_inverse=15, detailed=0, network_font_size=0)\n",
    "W.analyzer.network_fancy(animation_speed_inverse=15, sample_ratio=0.1, interval=10, trace_length=5)\n",
    "W.analyzer.network_anim(detailed=1, network_font_size=1, figsize=(12,12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get somewhat plausible results. Traffic from outskirts goes to the central Tokyo, causing traffic congestion due to the concentration. \n",
    "\n",
    "Note that the above results is not very realistic. To obtain realistic results, you have to calibrate demands and scenario parameters very carefully. This usually requires hard work."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
